{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf574b3-aadd-43f6-aa67-ab82651f0145",
   "metadata": {},
   "source": [
    "# Regresión logística: Regularización\n",
    "M2U5 - Ejercicio 5\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Implementar la función de coste y descenso de gradiente regularizadas\n",
    "- Comprobar el entrenamiento representando la evolución de la función de coste\n",
    "- Hallar el parámetro de regularización *lambda* óptimo por validación\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Una vez implementada la función de coste y gradient descent sin regularizar, vamos a regularizarlas y entrenar un modelo de regresión logística completo, comprobándolo por validación y evaluándolo sobre un subset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fe604-a17c-4c68-9415-c516cfd380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f7c59-0a6a-440c-80ac-5d172adaba24",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión logística\n",
    "\n",
    "Vamos a crear un dataset sintético de 2 clases únicamente (0 y 1) para comprobar esta implementación de un modelo de clasificación binaria, entrenado completamente, paso a paso.\n",
    "\n",
    "Para ello, crea un dataset sintético para regresión logística con término de bias y error de forma manual (para tener disponible *Theta_verd*) con el código que has usado en el ejercicio anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40f576-6ce6-493a-81d7-6e7134f200bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético con término de bias y error de forma manual\n",
    "m = 100\n",
    "n = 1\n",
    "\n",
    "# Genera un array 2D m x n con valores aleatorios entre -1 y 1\n",
    "# Insértale el término de bias como una primera columna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Genera un array de theta de n + 1 valores aleatorios entre [0, 1)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Calcula Y en función de X y Theta_verd\n",
    "# Transforma Y a valores de 1. y 0. (float) cuando Y >= 0.0\n",
    "# Con una probabilidad como término de error, itera sobre Y y modifica la clase asignada a la contraria, 1. a 0. y 0. a 1.\n",
    "error = 0.15\n",
    "\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a2aed3-82ba-4547-a2ae-50dcf3d4cea9",
   "metadata": {},
   "source": [
    "## Implementar la función de activación sigmoide\n",
    "\n",
    "Copia tu celda con la función sigmoide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a747e-c79e-4a24-b8e6-a8a8573e21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac98be5-1acb-4510-8c66-e58424203d63",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Al igual que hacíamos para la regresión lineal, vamos a preprocesar los datos completamente, siguiendo los 3 pasos habituales:\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento, validación y test.\n",
    "\n",
    "Puedes hacerlo manualmente o con las funciones auxiliares de Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1f14c-40a6-4c34-a455-25c3ff250484",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf1e1e-6330-4e27-8e5a-be7beba21b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943d24b-c888-4412-bab5-8033e478e681",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e6a10-0c2b-4a41-9fc9-39a88b922ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "# Copia tu función de normalización utilizada en la unidad de regresión lineal\n",
    "def normalize(x, mu, std):\n",
    "    pass\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b79868-e71c-4193-80b6-3132daac1823",
   "metadata": {},
   "source": [
    "*Nota*: Si habías modificado tu función *normalize* para que calculara y devolviera los valores de *mu* y *std*, puedes modificar esta celda para incluir tu código personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a1f3f-6347-4296-88c4-20f786029c9a",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, validación y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 3 subsets con el ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio por otro como 50/25/25 o 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e00607-f834-464e-99af-6b9e0146cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratio = [60, 20, 20]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1] + ratio[2])\n",
    "\n",
    "r = [0, 0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_val, X_test = [...]\n",
    "Y_train, Y_val, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85ef3b-dd5c-4c1e-a4df-d5937e31f4a8",
   "metadata": {},
   "source": [
    "## Implementar la función de activación sigmoide\n",
    "\n",
    "Copia tu celda con la función sigmoide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0c3a9-9f0e-4832-b795-4a3e349faafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b0553-219a-4f0d-89f0-11f4ea4e6c25",
   "metadata": {},
   "source": [
    "## Implementar la función de coste regularizada\n",
    "\n",
    "Vamos a implementar la función de coste regularizada. Esta función será similar a la que implementamos para regresión lineal en un ejercicio anterior.\n",
    "\n",
    "Función de coste regularizada:\n",
    "\n",
    "$$ Y = h_\\Theta(x) = g(X \\times \\Theta^T) $$\n",
    "$$ J(\\Theta) = - [\\frac{1}{m} \\sum\\limits_{i=0}^{m} (y^i log(h_\\theta(x^i)) + (1 - y^i) log(1 - h_\\theta(x^i))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\Theta_j^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7dd0bc-2987-4319-886c-01ce50e7133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función de coste regularizada para regresión logística\n",
    "\n",
    "def regularized_logistic_cost_function(x, y, theta, lambda_=0.):\n",
    "    \"\"\" Computa la función de coste para el dataset y coeficientes considerados\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- ndarray 2D con los valores de las variables independientes de los ejemplos, de tamaño m x n\n",
    "    y -- ndarray 1D con la variable dependiente/objetivo, de tamaño m x 1 y valores 0 o 1\n",
    "    theta -- ndarray 1D con los pesos de los coeficientes del modelo, de tamaño 1 x n (vector fila)\n",
    "    lambda_ -- factor de regularización, por defecto 0.\n",
    "    \n",
    "    Devuelve:\n",
    "    j -- float con el coste para dicho array theta\n",
    "    \"\"\"\n",
    "    m = [...]\n",
    "    \n",
    "    # Recuerda comprobar las dimensiones de la multiplicación matricial para hacerla correctamente\n",
    "    j = [...]\n",
    "    \n",
    "    # Regulariza para todo Theta excepto el término de bias (el primer valor)\n",
    "    j += [...]\n",
    "    \n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce13caa-cd63-4754-9bfa-692427d9581e",
   "metadata": {},
   "source": [
    "Comprueba tu implementación en las siguientes circunstancias:\n",
    "1. Para *lambda* = 0:\n",
    "    1. Usando *Theta_verd*, el coste debe ser 0.\n",
    "    1. Según los valores de *theta* se alejen de *Theta_verd*, el coste debe ser mayor.\n",
    "1. Para *lambda* != 0:\n",
    "    1. Usando *Theta_verd*, el coste debe ser mayor de 0.\n",
    "    1. Cuanto mayor es *lambda*, mayor es el coste.\n",
    "    1. El crecimiento del coste en función de *lambda* es exponencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7caff62-b979-43c3-acb7-ab1536115902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba tu implementación sobre el dataset\n",
    "\n",
    "theta = Theta_verd    # Modifica y comprueba varios valores de theta\n",
    "\n",
    "j = logistic_cost_function(X, Y, theta)\n",
    "\n",
    "print('Coste del modelo:')\n",
    "print(j)\n",
    "print('Theta comprobado y Theta real:')\n",
    "print(theta)\n",
    "print(Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab374ab0-348f-47b3-b19f-92b690610d49",
   "metadata": {},
   "source": [
    "Anota tus experimentos y resultados en esta celda (en Markdown o código):\n",
    "\n",
    "1. Experimento 1\n",
    "1. Experimento 2\n",
    "1. Experimento 3\n",
    "1. Experimento 4\n",
    "1. Experimento 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17253ad8-9665-4190-8fb5-da043f92900f",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar un modelo inicial para comprobar que nuestra implementación y el dataset trabajan correctamente, y posteriormente podremos entrenar un modelo con validación sin problema.\n",
    "\n",
    "Para ello, sigue los mismos pasos que seguiste para la regresión lineal:\n",
    "- Entrena un modelo inicial sin regularización.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución.\n",
    "- Si es necesario, modifica cualquier parámetro y reentrena el modelo. Usarás dichos parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste en regresión logística sin regularizar y la celda donde entrenabas el modelo, y modifícalas para el caso de la regresión logística regularizda.\n",
    "\n",
    "Recuerda las funciones de descenso de gradiente para regresión logística regularizada:\n",
    "\n",
    "$$ Y = h_\\Theta(x) = g(X \\times \\Theta^T) $$\n",
    "$$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_0^i $$\n",
    "$$ \\theta_j := \\theta_j - \\alpha [\\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i + \\frac{\\lambda}{m} \\theta_j]; \\space j \\in [1, n] $$\n",
    "$$ \\theta_j := \\theta_j (1 - \\alpha \\frac{\\lambda}{m}) - \\alpha \\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i; \\space j \\in [1, n] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e25d51-0191-47ec-9e35-0fe2df104a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda con el descenso de gradiente para regresión logística sin regularizar y modifícala para implementar la regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7e8f5-e69c-44c1-b918-e875509a1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar y comprueba que funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af06ed-1362-42df-b9ab-eda151c3bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e710b7-7e10-48b4-b110-ce1f880af6f4",
   "metadata": {},
   "source": [
    "### Comprobar la implementación\n",
    "\n",
    "Comprueba de nuevo tu implementación, al igual que hiciste en el ejercicio anterior.\n",
    "\n",
    "En esta ocasión, además, comprueba cómo con una *lambda* distinta a 0 la penalización hace que el coste sea mayor cuanto mayor sea esta *lambda*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29135cf0-3451-48a0-9d84-d5ce27c46105",
   "metadata": {},
   "source": [
    "### Comprobar si existe desviación o sobreajuste\n",
    "\n",
    "Al igual que hacíamos en la regresión lineal, vamos a comprobar si existe sobreajuste comparando el coste del modelo en el dataset de entrenamiento y de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26ac15-42a2-4f3d-bbb5-50128460f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba el coste del modelo sobre el dataset de entrenamiento y validación\n",
    "# Utiliza la Theta_final del modelo entrenado en ambos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294ecc3-1ab7-4c93-9f80-de6990e1ffb3",
   "metadata": {},
   "source": [
    "Recuerda que con un dataset sintético aleatorio es difícil que se diera un caso u otro, pero de esta forma podríamos apreciar dichos problemas de la siguiente forma:\n",
    "\n",
    "- Si el coste final en ambos subsets es alto, puede haber un problema de desviación o *bias*.\n",
    "- Si el coste final en ambos subsets es muy diferente entre sí, puede haber un problema de sobreajuste o *varianza*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6381277-2d83-48e8-ad23-f09a131c1b7f",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo por validación\n",
    "\n",
    "Del mismo modo que hemos hecho en ejercicios anteriores, vamos a optimizar nuestro parámetro de regularización por validación.\n",
    "\n",
    "Para ello vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar sobre el subset de entrenamiento, y evaluar su error o coste final sobre el subset de validación.\n",
    "\n",
    "Vamos a representar gráficamente el error de cada modelo vs el valor de *lambda* usado e implementar un código que elegirá automáticamente el modelo más óptimo de entre todos.\n",
    "\n",
    "Recuerda entrenar todos tus modelos en igualdad de condiciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20de71-246c-49e0-907d-2290019a6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_val\n",
    "\n",
    "# Usa de nuevo un espacio logarítmico entre 10 y 10^3 de 10 elementos con valores que comiencen por un decimal no-cero 1 o 3\n",
    "lambdas = [...]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada valor de lambda sobre X_train\n",
    "# Almacena su theta y error/coste final\n",
    "# Posteriormente, evalúa su coste total en el subset de validación\n",
    "\n",
    "# Almacena dicha información en los siguientes ndarrays, del mismo tamaño que lambdas\n",
    "j_train = [...]\n",
    "j_val = [...]\n",
    "theta_val = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53229f4a-5ce9-4b1d-9613-179a2aaa6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "# Completa con tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50326c71-7a1c-4931-a057-edbf9e129194",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo\n",
    "\n",
    "Copia el código de ejercicios anteriores, modificándolo si es necesario, para escoger el modelo con mayor precisión sobre el subset de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2146e3-1801-4307-a06c-a528c28474c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge el modelo y el valor de lambda óptimos, con el menor error sobre el subset de CV\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge las de menor coste en el subset de CV\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95dbd8-c54a-4252-b76f-bb1898b8e321",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre un subset de datos que no hemos usado para entrenarlo ni para escoger ningún hiper-parámetro.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los residuos sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd9907-032f-4198-b6d5-0c384ed159c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con las correspondientes theta y lambda\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c216f-eace-44c5-aa46-764cb3f91750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, calcula los residuos y represéntalos frente al índice de ejemplos (m)\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea8c8f-849c-477b-9bf5-82904d149ac9",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado, optimizado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f3b8d-e416-4dd6-bebb-7517f6b69a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
