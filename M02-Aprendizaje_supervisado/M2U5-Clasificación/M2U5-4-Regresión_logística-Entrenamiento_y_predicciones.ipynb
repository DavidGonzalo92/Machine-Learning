{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c3d42e-4278-4e97-80b1-29c7bd9dca9e",
   "metadata": {},
   "source": [
    "# Regresión logística: Entrenamiento y predicciones\n",
    "M2U5 - Ejercicio 4\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión logística\n",
    "- Preprocesar los datos\n",
    "- Implementar el entrenamiento del modelo por gradient descent\n",
    "- Comprobar el entrenamiento representando la evolución de la función de coste\n",
    "- Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Una vez implementada la función de coste, vamos a entrenar un modelo de regresión logística por gradient descent, comprobando nuestro entrenamiento, evaluándolo sobre un subset de test y finalmente realizando predicciones sobre el mismo.\n",
    "\n",
    "En esta ocasión trabajaremos con una regresión logística binaria, mientras que en otros ejercicios plantearemos una clasificación multiclase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75001ae7-ec7a-404c-b18e-626111215ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c8385-e9ef-4891-a6e1-5a32415301d0",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión logística\n",
    "\n",
    "Vamos a crear un dataset sintético de 2 clases únicamente (0 y 1) para comprobar esta implementación de un modelo de clasificación binaria, entrenado completamente, paso a paso.\n",
    "\n",
    "Para ello, crea un dataset sintético para regresión logística con término de bias y error de forma manual (para tener disponible *Theta_verd*) con el código que has usado en el ejercicio anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e34da-36ff-4d10-82aa-a23368c62f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético con término de bias y error de forma manual\n",
    "m = 100\n",
    "n = 1\n",
    "\n",
    "# Genera un array 2D m x n con valores aleatorios entre -1 y 1\n",
    "# Insértale el término de bias como una primera columna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Genera un array de theta de n + 1 valores aleatorios entre [0, 1)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Calcula Y en función de X y Theta_verd\n",
    "# Transforma Y a valores de 1. y 0. (float) cuando Y >= 0.0\n",
    "# Con una probabilidad como término de error, itera sobre Y y modifica la clase asignada a la contraria, 1. a 0. y 0. a 1.\n",
    "error = 0.15\n",
    "\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104d14f-d030-4080-8857-f5b87b7ec9bf",
   "metadata": {},
   "source": [
    "## Implementar la función de activación sigmoide\n",
    "\n",
    "Copia tu celda con la función sigmoide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c1160-8942-4119-93a1-c9fc9e51842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af47ac7-c02e-4e8c-8aa1-ec4ce7fa2109",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Al igual que hacíamos para la regresión lineal, vamos a preprocesar los datos completamente, siguiendo los 3 pasos habituales:\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento y test.\n",
    "\n",
    "Puedes hacerlo manualmente o con las funciones auxiliares de Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f6925-be52-4e3f-afe5-145319c40611",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a26f38-d730-456d-9154-7500c2d86b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659a404-06e7-4d25-b542-35c1a36332bb",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28586e-67db-4555-8e9f-606a17871561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "# Copia tu función de normalización utilizada en la unidad de regresión lineal\n",
    "def normalize(x, mu, std):\n",
    "    pass\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325eadb3-b554-48f1-8502-80f3bc962a5f",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 2 subsets con el ratio de 70%/30%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio más adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a5f7f-443b-43f9-8dd9-e18391a647d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 2 subsets según el ratio indicado\n",
    "\n",
    "ratio = [70, 30]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1])\n",
    "\n",
    "# Índice de corte\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_test = [...]\n",
    "Y_train, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc8050-7a75-4e4d-b118-495a09e6d759",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar un modelo inicial para comprobar que nuestra implementación y el dataset trabajan correctamente, y posteriormente podremos entrenar un modelo con validación sin problema.\n",
    "\n",
    "Para ello, sigue los mismos pasos que seguiste para la regresión lineal:\n",
    "- Entrena un modelo inicial sin implementar la regularización.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución.\n",
    "- Si es necesario, modifica cualquier parámetro y reentrena el modelo. Usarás dichos parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste en regresión logística, el gradient descent sin regularizar para regresión lineal y la celda donde entrenabas el modelo de regresión, y modifícalas para el caso de la regresión logística.\n",
    "\n",
    "Recuerda las funciones de descenso de gradiente para regresión logística:\n",
    "\n",
    "$$ Y = h_\\Theta(x) = g(X \\times \\Theta^T) $$\n",
    "$$ \\theta_j := \\theta_j - \\alpha [\\frac{1}{m} \\sum_{i=0}^{m}(h_\\theta (x^i) - y^i) x_j^i] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630ea2f-e1c7-477f-865f-f09bb26f4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda con la función de coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f44be2-e863-4856-b08a-04f639092ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda con la función de descenso de gradiente sin regularizar para regresión lineal y adáptala para regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21bacf5-2af3-4900-b810-2ff9edd7f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be70b0-10fe-482b-aa24-b2dcd4f38000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9108c89-0d80-4001-87d6-b21bd30c32b0",
   "metadata": {},
   "source": [
    "Comprueba tu implementación en estas circunstancias:\n",
    "1. Usando *Theta_verd*, el coste final debe ser prácticamente 0 y converger en un par de iteraciones.\n",
    "1. Según los valores de *theta* se alejen de *Theta_verd*, debe necesitar más iteraciones y la *theta_final* debe ser muy similar a la *Theta_verd*.\n",
    "\n",
    "Para ello recuerda que puedes modificar los valores de las celdas y reejecutarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1022f9-323e-4ff3-bcdd-030558f2f966",
   "metadata": {},
   "source": [
    "Anota tus experimentos y resultados en esta celda (en Markdown o código):\n",
    "1. Experimento 1\n",
    "1. Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad87473-1622-4e42-adb3-507d60607562",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre un subset de datos que no hemos usado para entrenarlo.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los residuos sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10047f-8f27-4994-aac1-045b1a030f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con la correspondientes theta\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc3271-f2b7-4672-9e1b-570647bbee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, calcula los residuos y represéntalos frente al índice de ejemplos (m)\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c322b-bbbe-4536-a62f-d460c20cdc43",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4170c69-9850-4069-89da-70d715e6b4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
