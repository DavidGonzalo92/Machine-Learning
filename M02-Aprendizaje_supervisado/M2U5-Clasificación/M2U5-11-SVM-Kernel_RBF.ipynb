{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfddb7f-4dab-49f6-8c98-b96f539571e9",
   "metadata": {},
   "source": [
    "# SVM: Kernel RBF\n",
    "M2U5 - Ejercicio 11\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Generar un dataset sintético de 2 clases (binario)\n",
    "- Preprocesar el dataset\n",
    "- Entrenar un modelo de clasificación por SVM sobre el mismo\n",
    "- Comprobar su idoneidad\n",
    "- Optimizar los hiper-parámetros de nuestro modelo por validación\n",
    "- Evaluar nuestro modelo\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Del mismo modo que habíamos hecho para la clasificación por regresión logística usando Scikit-learn, ahora vamos a usarlo para resolver problemas de clasificación por SVM.\n",
    "\n",
    "En concreto, vamos a usar su clasificador SVC con el kernel RBF (\"Radial Basis Function\"). El modelo SVC de Scikit-learn tiene varios kernels disponibles, y el kernel gaussiano en concreto no está entre ellos. Sin embargo, el kernel RBF está muy relacionado con él puesto que también parte de una clasificación \"radial\", y en proyectos reales puede ser más eficiente y tener más rendimiento que el gaussiano.\n",
    "\n",
    "Por ello, en lugar del kernel gaussiano usaremos el RBF.\n",
    "\n",
    "Este kernel de SVM tiene 2 parámetros:\n",
    "- *C*: La inversa del parámetro de regularización. Para valores mayores de *C*, se aceptará un margen entre clases menor si la función de decisión clasifica mejor los ejemplos de entrenamiento. Valores menores de *C* intentarán incrementar el margen entre clases, con una función de decisión más simple por lo tanto, con la posible desventaja de una menor precisión.\n",
    "- *Gamma*: Define lo lejos que llega la influencia de cada ejemplo, o la inversa del radio de influencia de los ejemplos seleccionados por el modelo como \"landmarks\". Valores menores significarán una influencia con mayor alcance y valores mayores una influencia mucho más cercana.\n",
    "\n",
    "Vamos a optimizar ambos parámetros usando validación cruzada.\n",
    "\n",
    "Como referencia para este ejercicio puedes usar estos enlaces de la documentación:\n",
    "- [SVM: Classification](https://scikit-learn.org/stable/modules/svm.html#classification)\n",
    "- [skelarn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "- [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html)\n",
    "- [Non-linear SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21428169-00d2-467b-924a-42816c8a5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09111ef7-73f9-4e58-8d5b-cfd93fd5ec05",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético de clasificación binaria\n",
    "\n",
    "Crea un dataset para clasificación de 2 clases con [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html).\n",
    "\n",
    "Recuerda usar parámetros que luego podamos modificar como el nº de ejemplos, características y clases, si queremos que esté desordenado o no, un estado aleatorio inicial constante, nº de clústeres, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36d327-eac4-4393-8f4e-99295fc7c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea un dataset sintético para clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a493b-8bd5-40a6-9924-caa503912a86",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Preprocesa los datos:\n",
    "- Reordénalos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test (usaremos CV por K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef9dfd-bdc2-4085-a165-fc96e55b1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff81c69-4dd3-44b8-9c8f-9618e3c00155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209dcf36-69b7-44db-a617-6cd7fe7f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divídelos en subsets de entrenamiento, CV y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8b49-e994-4c1b-883c-cacd605bbfe8",
   "metadata": {},
   "source": [
    "## Entrena un modelo de clasificación por SVM inicial\n",
    "\n",
    "Para comprobar el funcionamiento de nuestro clasificador SVC antes de optimizarlo por validación cruzada, vamos a entrenar un modelo inicial sobre el subset de entrenamiento y validarlo sobre el subset de test.\n",
    "\n",
    "Recuerda usar la función [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) para usar el esquema \"uno contra el resto\" (OVR).\n",
    "\n",
    "Usa los valores por defecto de *C* y *gamma* para no influir sobre su regularización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786f1ed-4904-4c4d-8927-22fb80dd7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de SVC sin modificar los parámetros de regularización sobre el subset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb5add-dd9c-411e-8835-b4e4a4abd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con su model.score() sobre el subset de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05334b7-cdc8-4d3f-b7ec-6349697e0e6b",
   "metadata": {},
   "source": [
    "Una forma muy gráfica de comprender mejor cómo trabajan los SVM y comprobar la precisión de tu modelo es representar el hiper-plano que ahora separa las clases, cuyo margen con las clases intentamos maximizar.\n",
    "\n",
    "Para representarlo, recuerda que puedes seguir el ejemplo de [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html) y modificar su código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6c85d-4e41-4ada-ad12-413a09c7d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el hiper-plano de separación con el margen de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7e6c0-84c3-42a8-873a-257d45017aa9",
   "metadata": {},
   "source": [
    "## Optimizar los hiper-parámetros de regularización por validación cruzada\n",
    "\n",
    "Ahora vamos a usar de nuevo [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para optimizar nuestros hiper-parámetros *C* y *gamma* por K-fold a la vez en esta ocasión, y representar sus posibles valores de forma visual.\n",
    "\n",
    "Un ejemplo para ello muy interesante como hemos refernciado es [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
    "\n",
    "Modifica su código para optimizar nuestro modelo sobre nuestro dataset sintético usando K-fold para optimizar *C* y *gamma*. Puedes usar el mismo rango logarítmico de valores para estos hiper-parámetros o adecuarlo a este dataset.\n",
    "\n",
    "*Nota*: Recuerda que hemos preprocesado el dataset previamente siguiendo nuestros métodos habituales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3fa65-d3ce-4954-89b6-6d8eb91e165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optimiza los hiper-parámetros de SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365236e2-550d-43d7-872c-1564c9a3fc97",
   "metadata": {},
   "source": [
    "*Nota*: A veces es una buena idea dividir el código en celdas diferentes para poder modificarlas y reejecutarlas independientemente, especialmente cuando lleve tiempo su ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f468afd-03ea-4b00-ae34-7a25eef7e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa los efectos de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd419fa3-5e40-4322-8ead-416628db9e57",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "- Muestra los coeficientes e intercept del mejor modelo.\n",
    "- Evalúa el mejor modelo sobre el subset de test inicial.\n",
    "- Representa las predicciones de las clases para comprobar los aciertos, fallos y el margen entre clases en el nuevo hiper-plano.\n",
    "\n",
    "Para representar las predicciones y el hiper-plano de margen entre clases, puedes volver a usar el código con el que evaluaste el modelo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0b921-f006-4ebf-99c0-1d3c1f3ca87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el mejor modelo sobre el subset de test inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f562b66-1084-4dec-a694-763cfe305064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Representa las predicciones, comprueba la precisión y el margen entre clases"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
