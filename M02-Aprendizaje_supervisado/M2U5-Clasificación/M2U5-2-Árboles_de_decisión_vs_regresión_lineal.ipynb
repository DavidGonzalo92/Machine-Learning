{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4551f26-d023-4bd9-8ec1-9a43d2fa387e",
   "metadata": {},
   "source": [
    "# Árboles de decisión vs regresión lineal\n",
    "M2U5 - Ejercicio 2\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Comparar la precisión y el comportamiento de los árboles de decisión frente a la regresión lineal tradicional\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "En algunas ocasiones se estima que los árboles de regresión pueden no tener tanta precisión y caer en más sobreajuste frente a la regresión lineal tradicional, especialmente con un alto nº de características.\n",
    "\n",
    "En este ejercicio, vamos a seguir los pasos habituales para entrenar 2 modelos de regresión lineal: un árbol de decisión y un Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d17daa-c83e-412e-a54f-239be941af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167a2c5-b0c7-4c20-b132-b4384b4858e2",
   "metadata": {},
   "source": [
    "## Generar un dataset sintético\n",
    "\n",
    "Genera un dataset sintético con un término de error algo acusado y pocas características, de forma manual o con Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb071ed8-13f5-4d76-b0f2-718502b9647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético, con pocas características y un término de error notable\n",
    "# No añadas término de bias a X\n",
    "\n",
    "m = 1000\n",
    "n = 9\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.3\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86c2fb-f9a1-44d6-bad3-fd6f7493e044",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "- Reordena los datos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: De nuevo usaremos K-fold para la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d42e9-6c01-4c53-b149-cdf8c8053d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente, normaliza los ejemplos y dividelos en subsets de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e140a60-9a78-46b9-b0dc-76ab0aa1ba44",
   "metadata": {},
   "source": [
    "## Optimizar los modelos por validación cruzada\n",
    "\n",
    "- Entrena un modelo por cada valor de regularización o profundidad máx. a considerar.\n",
    "- Entrénalos y evalúalos sobre una divisón del subset de entrenamiento por K-fold.\n",
    "- Escoge el modelo y su regularización óptimos.\n",
    "\n",
    "Considera unos parámetros similares a los de ejercicios pasados:\n",
    "- Profundidad máxima en el rango `[1, 8]`\n",
    "- Parámetro de regularización L2 *alpha* en el rango logarítmico `[0, 0.1]: 0.1, 0.01, 0.001, 0.0001`, etc.\n",
    "\n",
    "Puedes copiar las celdas de ejercicios anteriores y modificarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43793063-c934-4c8c-a205-26470fb7edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente sobre un fold de K-fold diferente para árbol de regresión y Lasso\n",
    "\n",
    "# Itera sobre los splits de K-fold necesarios, entrena tus modelos y evalúalos sobre el subset de CV\n",
    "mejor_tree = [...]\n",
    "mejor_lasso = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701fdad6-3161-4927-bb93-17d573673c1a",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar los mejores modelos de árbol de decisión y Lasso sobre el subset de test.\n",
    "\n",
    "Para ello, calcula sus métricas de MSE, RMSE y R^2 score y representa gráficamente las predicciones del modelo vs el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c65c62-3d3a-4eab-ac26-b45d2968567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 sobre el subset de test para mejor árbol y Lasso\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12355c1-9685-4b4d-af04-a755d191ccea",
   "metadata": {},
   "source": [
    "Finalmente, comprueba su posible desviación o sobreajuste y precisión final representando gráficamente los residuos de ambos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dfd58-fe9a-4a1d-a98d-423d05e789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente los residuos de ambos modelos como gráficos de líneas, con colores diferentes, vs el índice de los ejemplos (m)\n",
    "\n",
    "residuos_tree = [...]\n",
    "residuos_lasso = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63dc89-5b2d-45cf-9d6b-2cb31afb98e6",
   "metadata": {},
   "source": [
    "*¿Hay diferencias significativas entre ambos modelos? ¿Qué ocurre si variamos el error o el nº de características del dataset original, cómo responden ambos tipos de modelos?*\n",
    "\n",
    "Para el caso del árbol de regresión, tal vez no hayamos hecho la comparativa más justa, puesto que quedan otros hiper-parámetros que podemos modificar: [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "## *Bonus*: Optimización de todos los hiper-parámetros del árbol de decisión\n",
    "\n",
    "*¿Te atreves a usar [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) no sólo para optimizar max_depth, sino para todos los hiper-parámetros del árbol de regresión?*\n",
    "\n",
    "En la página de la documentación de GridSearchCV tienes un ejemplo que puedes tomar como referencia."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
