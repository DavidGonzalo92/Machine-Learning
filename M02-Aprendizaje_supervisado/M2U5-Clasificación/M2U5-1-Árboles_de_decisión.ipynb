{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e3e64e-14a0-4779-83f8-c94bf9837a8e",
   "metadata": {},
   "source": [
    "# Árboles de decisión: Scikit-learn\n",
    "M2U5 - Ejercicio 1\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Entrenar un modelo de regresión lineal por árboles de decisión\n",
    "- Detectar si se produce desviación o sobreajuste en el modelo\n",
    "- Optimizar los hiper-parámetros con validación\n",
    "- Evaluarlo sobre el subset de test\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Vamos a resolver un problema de regresión lineal multivariable similar al de ejercicios anteriores, pero esta vez usando un árbol de decisión para regresión lineal.\n",
    "\n",
    "Un ejemplo que puedes tener como referencia para este ejercicio: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95184942-7bea-4ee5-8d0c-656fb4c48320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1c0ae-9e95-43d4-8957-75d94c6d8f8f",
   "metadata": {},
   "source": [
    "## Generar un dataset sintético\n",
    "\n",
    "Genera un dataset sintético con un término de error algo acusado y pocas características, de forma manual o con Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ad192-bcbe-4785-88a9-3b5d93f7fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético, con pocas características y un término de error notable\n",
    "# No añadas término de bias a X\n",
    "\n",
    "m = 1000\n",
    "n = 2\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.3\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74217537-2ce8-4899-a3a2-4a4167403df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente en 3D el dataset para asegurarte que el término de error es suficientemente alto\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc5107-d438-4274-ae4b-276caacf5717",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "- Reordena los datos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: De nuevo usaremos K-fold para la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089aed7-ffe9-4fca-876b-1309f1c2bae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente, normaliza los ejemplos y dividelos en subsets de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bfae5-5e7d-4d73-8248-078475322835",
   "metadata": {},
   "source": [
    "## Entrena un modelo inicial\n",
    "\n",
    "Vamos a comenzar a explorar los modelos de árboles de decisión para regresión con un modelo inicial.\n",
    "\n",
    "Para ello, entrena un modelo de [sklearn.tree.DecissionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) sobre el subset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143acbfd-4652-44b5-ba0f-6b4c776c35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un árbol de regresión sobre el subset de entrenamiento con una profundidad máx. de 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694b7ab-2c5f-4e86-b054-f92c1be46861",
   "metadata": {},
   "source": [
    "Ahora comprueba la idoneidad del modelo evaluándolo sobre el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b9a6f-ca82-41ff-b085-41b772ef4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de test\n",
    "\n",
    "y_test_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a626f-e438-47c6-b378-9f94e7c592f1",
   "metadata": {},
   "source": [
    "*PREGUNTA:*\n",
    "*¿Crees que se da desviación o sobreajuste en dicho modelo?*\n",
    "\n",
    "Para ello, compara su precisión con la calculada sobre el subset de entrenamiento y responde en esta celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e6999-1e04-4944-b9bc-e21b94af45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 ahora sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb79b07-efd4-4f9c-a8ce-68d1b1fb23d6",
   "metadata": {},
   "source": [
    "Como decíamos, los árboles de decisión tienden a sobreajustar, a ajustarse demasiado a los datos usados para entrenarlo y a veces no poder predecir bien sobre nuevos ejemplos.\n",
    "\n",
    "Vamos a comprobarlo gráficamente entrenando otro modelo con una profundidad máxima mucho mayor, de 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4b2b5-06d3-4aa3-91e6-b7f5be9ddf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena otro árbol de regresión sobre el subset de entrenamiento con profundidad máx. de 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6fdca-0857-4f92-9947-8bfdf36645b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17f0d8-cf13-4c8f-b728-aeedf14e2cc2",
   "metadata": {},
   "source": [
    "Compara la precisión del entrenamiento de este modelo con el anterior (sobre el subset de entrenamiento).\n",
    "\n",
    "*PREGUNTA:* ¿Es mayor o menor al aumentar la profundidad máxima del árbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d66ae-7c62-4855-bfe3-ea9bce8e1626",
   "metadata": {},
   "source": [
    "Ahora vamos a representar gráficamente ambos modelos, para comprobar si sufren desviación o sobreajuste.\n",
    "\n",
    "Para hacerlo, puedes guiarte por el ejemplo anterior: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e172c-0a55-4d2d-8897-788bdea1521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones de ambos modelos\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de entrenamiento para la característica 1 y 2 (con formas diferentes)\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "# Representa en un gráfico de puntos el subset de test para la característica 1 y 2 (con formas diferentes), con un color diferente respecto al subset de entrenamiento\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones de ambos modelos, con colores diferentes y una leyenda para distinguirlos\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de ambas características de X\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94159082-275b-41f6-96fc-add6d750ef60",
   "metadata": {},
   "source": [
    "Como hemos podido comprobar, generalmente una profundidad máx. demasiado pequeña lleva a un modelo con desviación, un modelo que no es capaz de ajustar suficientemente bien la curva, mientras que una profundidad máx. demasiado alta lleva a un modelo con sobreajuste, un modelo que ajusta demasiado bien la curva, pero que no tiene una buena precisión en ejemplos futuros.\n",
    "\n",
    "Por tanto, entre todos los hiper-parámetros de los árboles de regresión, tenemos la profundidad máxima, que debemos optimizar por validación. También hay otros hiper-parámetros, como el criterio para medir la calidad de una división, la estrategia para crear esa división, el nº mín. de ejemplos necesario para dividir un nodo, etc.\n",
    "\n",
    "Por simpleza, vamos a comenzar realizando una validación cruzada sólo para hallar el valor óptimo de la profunidad máxima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232a8a6-5f03-4e35-a1ed-354c6b069bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente para cada valor de max_depth considerado sobre un fold diferente\n",
    "\n",
    "# Valores de max_depth a considerar en un espacio de nºs enteros [1, 8]\n",
    "max_depths = [...]\n",
    "print('Profundidades máx. a considerar:')\n",
    "print(max_depths)\n",
    "\n",
    "# Crea x splits de K-fold, uno por cada valor de max_depth a considerar\n",
    "kf = [...]\n",
    "\n",
    "# Itera sobre los splits, entrena tus modelos y evalúalos sobre el subset de CV generado\n",
    "linear_models = []\n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Entrena un modelo sobre el subset train\n",
    "    # Evalúalo sobre el subset cv usando su método score()\n",
    "    # Guarda el modelo con el mejor score en la variable best_model y muestra el alpha del mejor modelo\n",
    "    alpha = [...]\n",
    "    print('Profundidad máx. usada:', max_depth)\n",
    "    \n",
    "    linear_models.append([...])\n",
    "    \n",
    "    # Si el modelo es mejor que el mejor modelo hasta ahora, actualiza el mejor modelo encontrado\n",
    "    best_model = [...]\n",
    "    \n",
    "    print('Profundidad máx. y R^2 del mejor árbol hasta ahora:', max_depth, best_model.score([...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184ab37-bcf6-47e5-95a3-97af7ef39a4e",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre el subset de test.\n",
    "\n",
    "Para ello, calcula sus métricas de MSE, RMSE y R^2 y representa gráficamente las predicciones del modelo y residuos vs el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3137f-e553-41b7-a4b1-bece2e99d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE, RMSE y R^2 sobre el subset de test\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "rmse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: {%.2f}'.format(mse))\n",
    "print('Raíz del error cuadrático medio: {%.2f}'.format(rmse))\n",
    "print('Coeficiente de determinación: {%.2f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75456c34-bdf9-4d1c-8d92-986575db190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones del mejor árbol sobre el subset de test y sus residuos\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de test, mostrando ambas características con una forma diferente\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones del modelo\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de las características de X_test\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "# Calcula los residuos y represéntalos como un gráfico de barras sobre el eje horizontal\n",
    "residuals = [...]\n",
    "\n",
    "plt.bar([...]\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
