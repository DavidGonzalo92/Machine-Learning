{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c4fd02-5ac3-41a8-851e-4bd6c7e7e564",
   "metadata": {},
   "source": [
    "# Comparación de algoritmos de agrupación con Scikit-learn\n",
    "M3U2 - Ejercicio 3\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Comparar los diferentes algoritmos de agrupación disponibles en Scikit-learn\n",
    "- Comprobar las suposiciones iniciales para el caso de K-means\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "En este ejercicio no vas a desarrollar código nuevo, sino simplemente descargar y ejecutar 2 notebooks de la documentación de Scikit-learn:\n",
    "- [Comparing different clustering algorithms on toy datasets](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)\n",
    "- [Demonstration of k-means assumptions](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html)\n",
    "\n",
    "Como conclusiones podríamos añadir muchas, como p. ej.:\n",
    "- Ningún algoritmo de agrupación trabaja bien en todos los casos, con todas las distribuciones de datos posibles.\n",
    "- El análisis de datos previo es más necesario si cabe a la hora de entrenar algoritmos de agrupación.\n",
    "- La visualización previa nos ayudará mucho, aunque es bastante difícil sin reducción de dimensionalidad.\n",
    "- El problema de la agrupación es inherentemente difícil de resolver en muchas ocasiones.\n",
    "\n",
    "\n",
    "Copia las celdas de código de los ejemplos de la documentación, analiza los resultados, modifica algunos parámetros para experimentar y comprobar tu intuición y responde a las preguntas al final del ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d0ac4-1194-4ab9-a09c-0688c78df865",
   "metadata": {},
   "source": [
    "## Comparando diferentes algoritmos de agrupación en datasets de muestra\n",
    "\n",
    "El problema de la agrupación es un problema inherentemente difícil de resolver con precisión, puesto que no hay unos resultados previamente conocidos que podamos usar para supervisar nuestro aprendizaje, y la elección de clústeres correctos puede ser bastante difícil, además de ser siempre subjetiva.\n",
    "\n",
    "Hay muchos algoritmos de agrupación diferentes que podemos utilizar, además de K-means y sus variantes, y cada uno de ellos funcionará mejor o peor en función de la distribución de datos del dataset.\n",
    "\n",
    "Copia el código del ejercicio **Comparing different clustering algorithms on toy datasets** y compruébalo por ti mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92826d53-ade7-4a9c-8783-b8ee6b142a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ejecuta el código del ejercicio correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866ca24-31cd-47ec-ba18-b2c79574021a",
   "metadata": {},
   "source": [
    "## Demostración de las asumpciones del algoritmo de K-means\n",
    "\n",
    "En concreto, para el algoritmo de K-means y en general para sus variaciones, funcionará mal sobre datasets con las siguientes distribuciones de ejemplos:\n",
    "- Un nº incorrecto de blobs o clústeres utilizado para entrenar el modelo.\n",
    "- Datasets con formas no-esféricas muy juntos entre sí.\n",
    "- Varianza entre clústeres cercanos muy diferente entre sí.\n",
    "\n",
    "Por contra, funciona bastante bien en clústeres separados con una varianza similar, aunque el nº de ejemplos sea muy diferente.\n",
    "\n",
    "Copia el código del ejercicio **Demonstration of k-means assumptions** y compruébalo por ti mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077f7e4-3c57-4a67-8705-f9aae6cd998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ejecuta el código del ejercicio correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a653f4c-7adb-4730-88ab-dc9defb8621e",
   "metadata": {},
   "source": [
    "Modifica los parámetros del dataset utilizado para ver si las asumpciones se continúan cumpliendo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324b7d3-c07f-42a3-b3cb-c3747e07a9bf",
   "metadata": {},
   "source": [
    "## Preguntas a responder\n",
    "\n",
    "Por favor, responde las siguientes preguntas añadiendo tras esta celda de Markdown una nueva celda con tus respuestas siguiendo la misma lista. Hemos dividido las preguntas en 2 bloques, cada uno relativo a uno de los notebooks de la documentación de Scikit-learn, por lo que cuando hablemos de datasets y algoritmos nos referiremos a los de dicho notebook.\n",
    "\n",
    "### Comparando diferentes algoritmos de agrupación en datasets de muestra\n",
    "1. *PREGUNTA:* ¿Puedes describir con tus propias palabras los 6 datasets diferentes utilizados?\n",
    "    1.  Nota: Parece una pregunta tonta, pero aunque las diferencias son evidentes, tener que pararte a describir las diferencias te ayuda a fijarte realmente bien en ellas, y al documentarlo te servirá para luego ver si encaja con algunas características de otro dataset en la vida real.\n",
    "    1. Dataset 1:\n",
    "    1. Dataset 2:\n",
    "    1. Dataset 3:\n",
    "    1. Dataset 4:\n",
    "    1. Dataset 5:\n",
    "    1. Dataset 6:\n",
    "1. *PREGUNTA:* Compara los resultados de todos los algoritmos sobre los datasets. Dale una \"nota\" entre 1 y 5 a cada uno para compararlos:\n",
    "    1. Ejemplo: Ward: [1, 2, 2, 1, 5, 3]\n",
    "    1. Mini-batch KMeans: []\n",
    "    1. Affinity propagation: []\n",
    "    1. Mean shift: []\n",
    "    1. Spectral clustering: []\n",
    "    1. Ward: []\n",
    "    1. Agglomerative clustering: []\n",
    "    1. DB Scan: []\n",
    "    1. Optics: []\n",
    "    1. Birch: []\n",
    "    1. Gaussian mixture: []\n",
    "1. *PREGUNTA:* Elige el algoritmo más óptimo para resolver cada dataset o situación y justifica tu respuesta:\n",
    "    1. Dataset 1:\n",
    "    1. Dataset 2:\n",
    "    1. Dataset 3:\n",
    "    1. Dataset 4:\n",
    "    1. Dataset 5:\n",
    "    1. Dataset 6:\n",
    "    \n",
    "### Demostración de las asumpciones del algoritmo de K-means\n",
    "1. *PREGUNTA:* Al igual que has descrito los datasets en la pregunta anterior, describe este dataset (\"Unevenly sized blobs\"):\n",
    "    1. Respuesta:\n",
    "1. *PREGUNTA:* Para cada dataset o caso, describe la suposición de KMeans para poder aplicarlo correctamente que crees que cumple o inclumple.\n",
    "    1. Dataset 1:\n",
    "    1. Dataset 2:\n",
    "    1. Dataset 3:\n",
    "    1. Dataset 4:\n",
    "1. *PREGUNTA:* Para cada dataset o caso, ¿se te ocurre alguna posible transformación de los datos a otro espacio de variables o cualquier transformación de otro tipo que nos ayudara a resolver dicho problema con KMeans?\n",
    "    1. Nota: Es una pregunta compleja, no te preocupes si no tienes una respuesta para cada caso, o no se te ocurre nada, aunque te animamos a intentarlo :).\n",
    "    1. Dataset 1:\n",
    "    1. Dataset 2:\n",
    "    1. Dataset 3:\n",
    "    1. Dataset 4:"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
