{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd38404-070a-43e8-9555-103e08cb11ed",
   "metadata": {},
   "source": [
    "# Detección de anomalías: Comparación con clasificación\n",
    "M4U1 - Ejercicio 2\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para detección de anomalías con casos normales y anómalos\n",
    "- Entrenar 2 modelos de forma semi-supervisada y de clasificación por SVM\n",
    "- Evaluar ambos modelos y representar gráficamente sus resultados\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Los métodos de detección de anomalías por la covarianza de la distribución gaussiana y la baja probabilidad de un evento (usado en el ejercicio anterior) y por clasificación son similares, especialmente clasificamos con un SVM de kernel gaussiano, ya que ambos tratan de modelizar una distribución gaussiana sobre los datos.\n",
    "\n",
    "Sus principales diferencias se aprecian sólo en algunas circunstancias, p. ej.:\n",
    "- La distribución de los ejemplos normales no es gaussiana/normal o tiene múltiples centroides que no hemos detectado de antemano.\n",
    "- En un dataset de alta dimensionalidad, determinar la distribución normal de los datos es más difícil.\n",
    "- La clasificación, al ser un método de aprendizaje supervisado, necesita un porcentaje de datos anómalos superior al del aprendizaje reforzado.\n",
    "\n",
    "En este ejercicio vamos a combinar ambos métodos, que ya has resuelto en ejercicios anteriores, para analizar sus resultados y diferencias.\n",
    "\n",
    "Sigue las siguientes instrucciones para resolver el mismo dataset por detección de anomalías con distribución gaussiana y por SVM con kernel gaussiano, copiando celdas de código de ejercicios anteriores cuando sea posible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c6d95-9326-41fd-837b-e561142d20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Usa esta celda para importar todas las librerías necesarias\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ad07b-5c1c-4927-9b92-ca2ad1a89100",
   "metadata": {},
   "source": [
    "## Creación del dataset original\n",
    "\n",
    "Vamos a crear un dataset sintético siguiendo los mismos pasos que en el ejercicio de detección de anomalías anterior. Sin embargo, luego crearemos 2 conjuntos de datos diferentes, uno para deteccion de anomalías y otro para clasificación, cada uno con sus 3 subconjuntos de datos de entrenamiento, validación y test, ya que para la detección por covarianza de distribución gaussiana no asignábamos valores anómalos al subset de entrenamiento y para la clasificación por SVM sí lo necesitamos hacer.\n",
    "\n",
    "Los pasos que vamos a dar son:\n",
    "1. Crear un dataset de datos normales y otro de anómalos.\n",
    "1. Preprocesarlos, normalizarlos y reordenarlos aleatoriamente.\n",
    "1. Crear subsets de entrenamiento, validación y test para resolver por covarianza de distribución gaussiana, sin datos anómalos en el subset de entrenamiento.\n",
    "1. Crear subsets de entrenamiento, validación y test para resolver por SVM con kernel gaussiano, con datos anómalos distribuidos en todos los subsets.\n",
    "1. Representar gráficamente los datos de los 2 conjuntos de subsets.\n",
    "\n",
    "Por tanto, completa las siguientes celdas de código, copiando tu código de ejercicios anteriores siempre que sea posible. Al final debes haber generado, normalizado, dividido y reordenado los ndarray *X_cdg_train, X_cdg_val, X_cdg_test, X_svm_train, X_svm_val, X_svm_test* y sus *Y* correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a1ff3-3553-467b-9334-e93847fd0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera dos datasets sintéticos independientes con datos normales y anómalos\n",
    "\n",
    "m = 1000\n",
    "n = 2\n",
    "ratio_anomalos = 0.25    # Porcentaje de datos anómalos vs datos normales, modificable\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb55a05-3d4c-4b5e-9f94-e87565edf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos de ambos datasets con los mismos parámetros de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f52e9-e387-47ec-a267-6f216dc3ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente los 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf16730-4afc-4fc4-bd57-c5db85107265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el 1er dataset en subsets de entrenamiento, validación y test para covarianza de dist. gaussiana, con datos anómalos sólo en validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce249e-37a8-4627-9dc3-d326951c54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el 2º dataset en subsets de entrenamiento, validación y test para clasificación por SVM de kernel gaussiano, con datos anómalos distribuidos en todos los subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd2e62-daf3-4913-a851-ac8dba830ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para ambos casos, representa los 3 subsets en una gráfica 2D indicando los datos normales y anómalos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de1756-e7f1-4a8c-aeee-74e6cdddadfe",
   "metadata": {},
   "source": [
    "## Resolución por deteccion de anomalías por covarianza de la distribución normal\n",
    "\n",
    "Para resolver el dataset por covarianza de la distribución normal, sigue los pasos del ejercicio anterior, copiando el código de las celdas correspondientes y usando los subsets adecuados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb11a2-1c57-40d2-a531-48c7ff240724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modeliza la distribución gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069e298-0b08-47c4-9191-f3f66f9d4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Determina el umbral de probabilidad para detectar casos anómalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37ab6e-bf56-44ae-9c02-d443dce525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa la precisión final del modelo con su F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581637dc-e187-4123-95e1-944d94bbffab",
   "metadata": {},
   "source": [
    "## Resolución por clasificación por SVM\n",
    "\n",
    "Del mismo modo, sigue los pasos de los ejercicios sobre SVM anteriores para clasificar los datos en normales y anómalos por SVM, copiando el código de las celdas correspondientes y usando los subsets adecuados.\n",
    "\n",
    "Utiliza un kernel RBF con el método de Scikit-learn [OneClassSVM](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html) y *ratio_anomalos* como parámetro *nu*. Para regularizar el modelo, optimiza *gamma* con [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddafc71-5ab0-48f7-8474-ddf0b9376005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de OneClassSVM y optimiza gamma en el subset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37e6e2-8ccf-4164-b5ce-611ce60e8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa la precisión final del modelo con su F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0158269-7f0d-4a3e-8174-0e07ebda69df",
   "metadata": {},
   "source": [
    "## Comparación de los resultados de ambos métodos\n",
    "\n",
    "Ahora compara ambos métodos, mostrando su F1-score y representando gráficamente sus resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82776449-2ab4-4449-8afa-f9dc29550dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Muestra los resultados de la F1-score de ambos modelos\n",
    "\n",
    "print('F1-score de la covarianza de la distribución gaussiana:')\n",
    "print()\n",
    "print('F1-score de la clasificación por SVM:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56050573-161e-4a05-bb49-e4bdc1df9c15",
   "metadata": {},
   "source": [
    "Representa los resultados de ambos modelos en sus subsets de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615975d1-b4ee-4625-b6d6-2bb55daa6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa errores y aciertos junto a la distribución y la línea de contorno del umbral de corte de epsilon\n",
    "# para la covarianza de la distribución gaussiana\n",
    "\n",
    "# Asigna z = 1. para acierto y z = 0. para fallo\n",
    "# Acierto: Y_test == Y_test_pred\n",
    "z_cdg = [...]\n",
    "\n",
    "# Representa la gráfica 2D\n",
    "# Utiliza colores diferentes para aciertos y fallos\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed1cd3-8475-4dff-a905-490b7981899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa errores y aciertos junto a la distribución y la frontera entre clases\n",
    "# para la clasificación por SVM\n",
    "\n",
    "# Asigna z = 1. para acierto y z = 0. para fallo\n",
    "# Acierto: Y_test == Y_test_pred\n",
    "z_svm = [...]\n",
    "\n",
    "# Representa la gráfica\n",
    "# Utiliza colores diferentes para aciertos y fallos\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efe636-82b7-41b5-b2ff-d5f93887856a",
   "metadata": {},
   "source": [
    "*¿Qué conclusiones puedes sacar? ¿Qué diferencias hay entre ambos métodos?*"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
